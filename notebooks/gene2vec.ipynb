{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene2Vec Experiments\n",
    "Attempting to recreate results of [gene2vec paper](https://doi.org/10.1186/s12864-018-5370-x)\n",
    "\n",
    "1. [Import known gene pathways from MSigDB](#pathways)\n",
    "2. [Generate pairs of genes from gene pathway sets](#pairs)\n",
    "3. [Use `gensim` to train with gene2vec](#gensim)\n",
    "4. [Visualise embeddings with PCA and tSNE](#vis)\n",
    "5. [Load and preprocess somatic mutations from TCGA in BigQuery](#tcga)\n",
    "6. [Produce 2D images for every sample](#2d)\n",
    "7. [Model Training](#) \n",
    "    - 7.1 [Random Forest (baseline on sparse samples)](#)\n",
    "    - 7.2 [XGBoost on images](#)\n",
    "    - 7.3 [CNN (on images only)](#)\n",
    "    - 7.4 [CNN w ImageNet weight initialisation (FastAI)](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import known gene pathways from [MSigDB](http://software.broadinstitute.org/gsea/msigdb/collections.jsp)\n",
    "<a id=\"pathways\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word2vec parameters\n",
    "dimension = 100     # dimension of the embedding\n",
    "num_workers = 8     # number of worker threads\n",
    "sg = 1              # sg =1, skip-gram, sg =0, CBOW\n",
    "max_iter = 10       # number of iterations\n",
    "window_size = 1     # The maximum distance between the gene and predicted gene within a gene list\n",
    "negative = 3        # number of negative samples\n",
    "txtOutput = True\n",
    "\n",
    "# Environment variables\n",
    "MSIGDB = '../data/gene2vec/msigdb.v6.2.symbols.gmt'\n",
    "TCGA = '../data/gene2vec/processed_somatic_mutations_subset2'\n",
    "INTOGEN = '../data/gene2vec/intogen-drivers-data.tsv'\n",
    "GENE2VEC_DIR = '../experiments/gene2vec/models/'\n",
    "FILENAME = 'gene2vec_dim_{0:d}_iter_'.format(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(line):\n",
    "    name, _, genes = line.split(\"\\t\", 2)\n",
    "    return name, set(gene.replace('\\n', '') for gene in genes.split(\"\\t\"))\n",
    "\n",
    "with open(MSIGDB, 'r') as fp:\n",
    "    pathways_df = pd.DataFrame(data=[_get_data(line) for line in fp],\n",
    "                               columns=[\"name\", \"set\"])\n",
    "\n",
    "pathways_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate pairs of genes from gene pathway sets\n",
    "<a id=\"pairs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_subset = pathways_df.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gene_pairs(gene_set):\n",
    "    from itertools import combinations\n",
    "    # Get all combinations of length 2 \n",
    "    pairs = combinations(list(gene_set), 2)\n",
    "    return set(pairs)\n",
    "\n",
    "def get_pairs_set(df):\n",
    "    \"\"\"\n",
    "    Return the set union of all pairs from every gene set within the df.\n",
    "    \"\"\"\n",
    "    return set.union(*df['pairs'].tolist())\n",
    "\n",
    "pathways_subset['pairs'] = (pathways_subset.set\n",
    "                                           .apply(generate_gene_pairs))\n",
    "\n",
    "# total set of pairs without any duplication across samples\n",
    "total_set = pathways_subset.pipe(get_pairs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use [`gensim`](https://radimrehurek.com/gensim/models/word2vec.html) to train with gene2vec\n",
    "<a id=\"gene2vec\"></a>\n",
    "- With a c compile installed `gensim` offers a [70x speedup compared to plain NumPy implementation](https://rare-technologies.com/parallelizing-word2vec-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(gene_pairs):\n",
    "    # initialise and save model\n",
    "    model = gensim.models.Word2Vec(gene_pairs, \n",
    "                                   size=dimension, \n",
    "                                   window=window_size, \n",
    "                                   min_count=1, \n",
    "                                   workers=num_workers, \n",
    "                                   max_iter=max_iter, \n",
    "                                   negative=negative,\n",
    "                                   sg=sg)\n",
    "    print(\"gene2vec model initialised\")\n",
    "    current_iter = 0\n",
    "    model.save(GENE2VEC_DIR + FILENAME + str(current_iter))\n",
    "    print(\"gene2vec model saved\")\n",
    "    del model \n",
    "    \n",
    "    # train model\n",
    "    for current_iter in range(1,max_iter+1):\n",
    "        # shuffle pairs\n",
    "        random.shuffle(gene_pairs)\n",
    "        \n",
    "        # load model and train on shuffled gene pairs\n",
    "        model = gensim.models.Word2Vec.load(GENE2VEC_DIR + FILENAME + str(current_iter-1))\n",
    "        model.train(gene_pairs,total_examples=model.corpus_count,epochs=model.iter)\n",
    "        model.save(GENE2VEC_DIR + FILENAME + str(current_iter))\n",
    "        print(\"gene2vec dimension \" + str(dimension) + \" iteration \" + str(current_iter) + \" start\")\n",
    "        del model\n",
    "        \n",
    "train_word2vec(list(total_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Visualise embeddings with PCA and tSNE\n",
    "<a id=\"vis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and train on shuffled gene pairs\n",
    "current_iter = 9\n",
    "filename = GENE2VEC_DIR + FILENAME + str(current_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "def load_embeddings(file_name):\n",
    "    model = KeyedVectors.load(file_name)\n",
    "    wordVector = model.wv\n",
    "    vocabulary, wv = zip(*[[word, wordVector[word]] for word, vocab_obj in wordVector.vocab.items()])\n",
    "    return np.asarray(wv), vocabulary\n",
    "\n",
    "# load test file\n",
    "wv, vocabulary = load_embeddings(filename)\n",
    "\n",
    "# shuffle index of genes\n",
    "indexes = list(range(len(wv)))\n",
    "random.shuffle(indexes)\n",
    "\n",
    "topN = len(wv) # for now select all genes\n",
    "rdWV = wv[indexes][:topN][:]\n",
    "rdVB = np.array(vocabulary)[indexes][:topN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv.shape, rdWV.shape, rdVB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(data, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('dimension 1', fontsize = 15)\n",
    "    ax.set_ylabel('dimension 2', fontsize = 15)\n",
    "    ax.set_title(title, fontsize = 20)\n",
    "    \n",
    "    ax.scatter(data[:,0], data[:,1], s = 5, alpha=0.5)\n",
    "    ax.grid()\n",
    "\n",
    "# 2 component PCA visualisation\n",
    "pca_2 = PCA(n_components=2)\n",
    "pca_2.fit(rdWV)\n",
    "pca_rdWV_2=pca_2.transform(rdWV)\n",
    "\n",
    "# plot\n",
    "plot_2d(pca_rdWV_2, title='2 Component PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 component PCA for tSNE\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(rdWV)\n",
    "pca_rdWV=pca.transform(rdWV)\n",
    "\n",
    "def tsne_worker(n_iter):\n",
    "    # 2 component tSNE applied to PCA\n",
    "    tsne = TSNE(n_components=2, \n",
    "                perplexity=30, \n",
    "                n_iter=n_iter, \n",
    "                learning_rate=200, \n",
    "                n_jobs=8)\n",
    "    \n",
    "    print('n_iter = {0:d} started'.format(n_iter))\n",
    "    data = tsne.fit_transform(pca_rdWV)\n",
    "    print('n_iter = {0:d} finished'.format(n_iter))\n",
    "    return data, n_iter\n",
    "    \n",
    "p = Pool(4)\n",
    "    \n",
    "# generate tsne of different iteration in parallel\n",
    "results = p.map(tsne_worker, [100, 500, 1000])\n",
    "\n",
    "# plot tSNE\n",
    "for data, n_iter in results:\n",
    "    plot_2d(data, '2D tSNE, n_iter={0:d}'.format(n_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Load and preprocess somatic mutations from [TCGA in BigQuery]\n",
    "(https://bigquery.cloud.google.com/table/isb-cgc:TCGA_hg38_data_v0.Somatic_Mutation?pli=1)\n",
    "<a id=\"tcga\"></a>\n",
    "\n",
    "- Subset query has already been completed in BQ and saved to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_raw = pd.read_csv(TCGA)\n",
    "tcga_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_distributions(df, title):\n",
    "    \"\"\"\n",
    "    Plot distribution and frequency of features of interest for raw and processed TCGA df.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize = (20,8))\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(hspace=0.6)\n",
    "    \n",
    "    df.groupby('case_barcode').head(1)['project_short_name'].value_counts() \\\n",
    "        .plot(kind='bar', title='Cases per Cancer type', ax=axes[0,0], color='m')\n",
    "    \n",
    "    df['Variant_Classification'] \\\n",
    "        .value_counts().plot(kind='bar', title='Variants per variant type', ax=axes[1,0], logy=True, color='g')\n",
    "    \n",
    "    df['case_barcode'].value_counts() \\\n",
    "        .plot(title='Log Variants per case, {0:d} cases'\n",
    "              .format(df['case_barcode'].value_counts().shape[0]), \n",
    "              ax=axes[0, 1],  logy=True, color='r')\n",
    "    \n",
    "    df['Hugo_Symbol'].value_counts() \\\n",
    "        .plot(title='Log Variants per gene, {0:d} genes'\n",
    "              .format(df['Hugo_Symbol'].value_counts().shape[0]), \n",
    "              ax=axes[1, 1], logy=True, color='b')\n",
    "    \n",
    "visualise_distributions(tcga_raw, 'Raw TCGA Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In absence of MutSigCV results use list of 459 driver genes from [Intogen](https://www.intogen.org/search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_mut_count(df, feature, cutoff=100):\n",
    "    \"\"\"\n",
    "    Drop rows which contain features which occur less than cutoff times in the dataset.\n",
    "    \"\"\"\n",
    "    subsample = df[feature].value_counts()[(df[feature].value_counts() > cutoff)].index.tolist()\n",
    "    return df[df[feature].isin(subsample)]\n",
    "\n",
    "def merge_label(df, label1, label2, merged_label):\n",
    "    \"\"\"\n",
    "    Merge label1 and label2 into merged label within dataframe.\n",
    "    \"\"\"\n",
    "    df.loc[(df['project_short_name'] == label1) | \n",
    "           (df['project_short_name'] == label2), 'project_short_name'] = merged_label\n",
    "    return df\n",
    "\n",
    "def process_labels(df):\n",
    "    \"\"\"\n",
    "    Merge cancers that are established clinically to be the same.\n",
    "    \"\"\"\n",
    "    # Colon and Rectal cancers are now considered the same cancer\n",
    "    # COAD, READ -> COADREAD\n",
    "    df = merge_label(df, 'TCGA-COAD', 'TCGA-READ', 'MERGE-COADREAD')\n",
    "    \n",
    "    # GBM and LGG are both forms of brain Glioma\n",
    "    # GBM, LGG   -> GBMLGG\n",
    "    df = merge_label(df, 'TCGA-GBM', 'TCGA-LGG', 'MERGE-GBMLGG')\n",
    "    \n",
    "    # Stomach and Esophegal cancers are also considered the same\n",
    "    # ESCA, STAD -> STES\n",
    "    df = merge_label(df, 'TCGA-ESCA', 'TCGA-STAD', 'MERGE-STES')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_intogen_drivers(df):\n",
    "    \"\"\"\n",
    "    Filter only genes that intersect with listed drivers from Intogen.\n",
    "    \"\"\"\n",
    "    intogen_drivers = pd.read_csv(INTOGEN, sep='\\t')\n",
    "    driver_genes = intogen_drivers['SYMBOL'].tolist()\n",
    "    return df[df['Hugo_Symbol'].isin(driver_genes)]\n",
    "\n",
    "def filter_variants(df):\n",
    "    \"\"\"\n",
    "    Filter out variants according to a list provided by Dr Nic Waddel (QIMR).\n",
    "    \"\"\"\n",
    "    \n",
    "    waddell_list = ['missense_variant',\n",
    "                    'stop_gained',\n",
    "                    'frameshift_variant',\n",
    "                    'splice_acceptor_variant',\n",
    "                    'splice_donor_variant',\n",
    "                    'start_lost',\n",
    "                    'inframe_deletion',\n",
    "                    'inframe_insertion',\n",
    "                    'stop_lost']\n",
    "    \n",
    "    return df[df['One_Consequence'].isin(waddell_list)]\n",
    "    \n",
    "# empirical dim reduction\n",
    "df_proc1 = (tcga_raw.pipe(process_labels)\n",
    "                    .pipe(filter_variants)\n",
    "                    .pipe(filter_intogen_drivers))\n",
    "\n",
    "# statistical dim reductions\n",
    "df_proc2 = (tcga_raw.pipe(process_labels)\n",
    "                    .pipe(filter_variants)\n",
    "                    .pipe(drop_low_mut_count, 'Hugo_Symbol', 200))     # naÃ¯vely remove very genes with few mutations as noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_distributions(df_proc1, 'Empirical Dim Reduction')\n",
    "visualise_distributions(df_proc2, 'Statistical Dim Reduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup_and_get_variant_count(df_in):\n",
    "    \"\"\"\n",
    "    Deduplicate gene sample combinations with >1 mutations and aggregate \n",
    "    with additional feature of variant count for gene sample combination.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    counts = df.groupby('case_barcode')['Hugo_Symbol'].value_counts()\n",
    "    df = df.drop_duplicates(subset=['case_barcode', 'Hugo_Symbol'])\n",
    "    df = df.set_index(['case_barcode', 'Hugo_Symbol'])\n",
    "    df['mutation_count'] = counts\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reshape_pivot(df_in):\n",
    "    \"\"\"\n",
    "    Reduce df to crucial subset then pivot on cases and genes.\n",
    "    \"\"\"\n",
    "    df = (df_in[['case_barcode', 'Hugo_Symbol', 'mutation_count']]\n",
    "              .copy()\n",
    "              .pivot(index='case_barcode', columns='Hugo_Symbol', values='mutation_count')\n",
    "              .fillna(0)\n",
    "              .astype(int))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_pivot1 = (df_proc1.pipe(dedup_and_get_variant_count)\n",
    "                     .pipe(reshape_pivot))\n",
    "\n",
    "df_pivot2 = (df_proc2.pipe(dedup_and_get_variant_count)\n",
    "                     .pipe(reshape_pivot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Produce 2D images for every sample\n",
    "<a id=\"2d\"></a>\n",
    "\n",
    "For each sample, now want to encode gene2vec embeddings as a prior on mutation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot1.shape\n",
    "df_pivot2.shape\n",
    "\n",
    "def convert_to_onehot(df_in):\n",
    "    \"\"\"\n",
    "    Convert count encoding to one-hot encoded representation of df.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    df[df != 0] = 1\n",
    "    return df\n",
    "\n",
    "def get_embedding_matrix(gene_list):\n",
    "    \n",
    "    \n",
    "def embed_gene_vectors(sample):\n",
    "    return\n",
    "\n",
    "def apply_spectral_clustering(image):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = convert_to_onehot(df_pivot1)\n",
    "test.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wv), len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test file\n",
    "wv, vocabulary = load_embeddings(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genevec = pd.DataFrame(wv.transpose(), columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    if '\\n' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
